{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'thor': 25, 'eating': 10, 'pizza': 22, 'loki': 16, 'is': 15, 'ironman': 14, 'ate': 7, 'already': 0, 'apple': 5, 'announcing': 4, 'new': 19, 'iphone': 13, 'tomorrow': 26, 'tesla': 24, 'model': 18, 'google': 12, 'pixel': 21, 'microsoft': 17, 'surface': 23, 'amazon': 2, 'eco': 11, 'dot': 9, 'am': 1, 'biryani': 8, 'and': 3, 'you': 27, 'are': 6, 'pilav': 20}\n"
     ]
    }
   ],
   "source": [
    "# Import TfidfVectorizer from the sklearn library to convert text data into TF-IDF features\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "# Define a corpus, which is a list of documents (strings) to analyze\n",
    "corpus = [\n",
    "    \"Thor eating pizza, Loki is eating pizza, Ironman ate pizza already\",\n",
    "    \"Apple is announcing new iphone tomorrow\",\n",
    "    \"Tesla is announcing new model-3 tomorrow\",\n",
    "    \"Google is announcing new pixel-6 tomorrow\",\n",
    "    \"Microsoft is announcing new surface tomorrow\",\n",
    "    \"Amazon is announcing new eco-dot tomorrow\",\n",
    "    \"I am eating biryani and you are eating pilav\"\n",
    "]\n",
    "\n",
    "# Create an instance of TfidfVectorizer which will be used to convert the corpus into a TF-IDF matrix\n",
    "v = TfidfVectorizer()\n",
    "\n",
    "# Fit the TfidfVectorizer to the corpus and transform the corpus into a TF-IDF matrix\n",
    "transform_output = v.fit_transform(corpus)\n",
    "\n",
    "# Print the vocabulary, which is a dictionary mapping each word in the corpus to its index in the TF-IDF matrix\n",
    "print(v.vocabulary_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['already', 'am', 'amazon', 'and', 'announcing', 'apple', 'are',\n",
       "       'ate', 'biryani', 'dot', 'eating', 'eco', 'google', 'iphone',\n",
       "       'ironman', 'is', 'loki', 'microsoft', 'model', 'new', 'pilav',\n",
       "       'pixel', 'pizza', 'surface', 'tesla', 'thor', 'tomorrow', 'you'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get a list of all the feature names (words) from the fitted TfidfVectorizer\n",
    "all_feature_name = v.get_feature_names_out()\n",
    "\n",
    "# Simply display the feature names as an array\n",
    "all_feature_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "already 2.386294361119891\n",
      "am 2.386294361119891\n",
      "amazon 2.386294361119891\n",
      "and 2.386294361119891\n",
      "announcing 1.2876820724517808\n",
      "apple 2.386294361119891\n",
      "are 2.386294361119891\n",
      "ate 2.386294361119891\n",
      "biryani 2.386294361119891\n",
      "dot 2.386294361119891\n",
      "eating 1.9808292530117262\n",
      "eco 2.386294361119891\n",
      "google 2.386294361119891\n",
      "iphone 2.386294361119891\n",
      "ironman 2.386294361119891\n",
      "is 1.1335313926245225\n",
      "loki 2.386294361119891\n",
      "microsoft 2.386294361119891\n",
      "model 2.386294361119891\n",
      "new 1.2876820724517808\n",
      "pilav 2.386294361119891\n",
      "pixel 2.386294361119891\n",
      "pizza 2.386294361119891\n",
      "surface 2.386294361119891\n",
      "tesla 2.386294361119891\n",
      "thor 2.386294361119891\n",
      "tomorrow 1.2876820724517808\n",
      "you 2.386294361119891\n"
     ]
    }
   ],
   "source": [
    "all_feature_name = v.get_feature_names_out()\n",
    "\n",
    "# Loop through each word (feature) in the TF-IDF vocabulary\n",
    "for word in all_feature_name:\n",
    "    # Get the index of the word in the TF-IDF matrix from the vocabulary\n",
    "    index = v.vocabulary_.get(word)\n",
    "    # Print the word along with its Inverse Document Frequency (IDF) score\n",
    "    print(f\"{word} {v.idf_[index]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Thor eating pizza, Loki is eating pizza, Ironman ate pizza already',\n",
       " 'Apple is announcing new iphone tomorrow']"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Display the first two documents in the corpus\n",
    "corpus[:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.24266547, 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.24266547, 0.        , 0.        ,\n",
       "        0.40286636, 0.        , 0.        , 0.        , 0.24266547,\n",
       "        0.11527033, 0.24266547, 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.72799642, 0.        , 0.        ,\n",
       "        0.24266547, 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.30652086,\n",
       "        0.5680354 , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.5680354 , 0.        ,\n",
       "        0.26982671, 0.        , 0.        , 0.        , 0.30652086,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.30652086, 0.        ]])"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Convert the TF-IDF matrix to a dense array and display the TF-IDF scores of the first two documents\n",
    "transform_output.toarray()[:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(24000, 2)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Urban Ladder Eisner Low Back Study-Office Comp...</td>\n",
       "      <td>Household</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Contrast living Wooden Decorative Box,Painted ...</td>\n",
       "      <td>Household</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>IO Crest SY-PCI40010 PCI RAID Host Controller ...</td>\n",
       "      <td>Electronics</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ISAKAA Baby Socks from Just Born to 8 Years- P...</td>\n",
       "      <td>Clothing &amp; Accessories</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Indira Designer Women's Art Mysore Silk Saree ...</td>\n",
       "      <td>Clothing &amp; Accessories</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                Text                   label\n",
       "0  Urban Ladder Eisner Low Back Study-Office Comp...               Household\n",
       "1  Contrast living Wooden Decorative Box,Painted ...               Household\n",
       "2  IO Crest SY-PCI40010 PCI RAID Host Controller ...             Electronics\n",
       "3  ISAKAA Baby Socks from Just Born to 8 Years- P...  Clothing & Accessories\n",
       "4  Indira Designer Women's Art Mysore Silk Saree ...  Clothing & Accessories"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Import the pandas library for handling data in tabular format\n",
    "import pandas as pd\n",
    "\n",
    "# Load a CSV file containing e-commerce data into a DataFrame\n",
    "df = pd.read_csv(\"Ecommerce_data.csv\")\n",
    "\n",
    "# Print the shape (number of rows and columns) of the DataFrame\n",
    "print(df.shape)\n",
    "\n",
    "# Display the first few rows of the DataFrame\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "label\n",
       "Household                 6000\n",
       "Electronics               6000\n",
       "Clothing & Accessories    6000\n",
       "Books                     6000\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Display the count of each label in the 'label' column\n",
    "df.label.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Text</th>\n",
       "      <th>label</th>\n",
       "      <th>label_num</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Urban Ladder Eisner Low Back Study-Office Comp...</td>\n",
       "      <td>Household</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Contrast living Wooden Decorative Box,Painted ...</td>\n",
       "      <td>Household</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>IO Crest SY-PCI40010 PCI RAID Host Controller ...</td>\n",
       "      <td>Electronics</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ISAKAA Baby Socks from Just Born to 8 Years- P...</td>\n",
       "      <td>Clothing &amp; Accessories</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Indira Designer Women's Art Mysore Silk Saree ...</td>\n",
       "      <td>Clothing &amp; Accessories</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                Text                   label  \\\n",
       "0  Urban Ladder Eisner Low Back Study-Office Comp...               Household   \n",
       "1  Contrast living Wooden Decorative Box,Painted ...               Household   \n",
       "2  IO Crest SY-PCI40010 PCI RAID Host Controller ...             Electronics   \n",
       "3  ISAKAA Baby Socks from Just Born to 8 Years- P...  Clothing & Accessories   \n",
       "4  Indira Designer Women's Art Mysore Silk Saree ...  Clothing & Accessories   \n",
       "\n",
       "   label_num  \n",
       "0          0  \n",
       "1          0  \n",
       "2          1  \n",
       "3          2  \n",
       "4          2  "
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Map the text labels to numerical labels and store them in a new column 'label_num'\n",
    "df[\"label_num\"] = df.label.map({\n",
    "    \"Household\": 0,\n",
    "    \"Electronics\": 1,\n",
    "    \"Clothing & Accessories\": 2,\n",
    "    \"Books\": 3,\n",
    "})\n",
    "\n",
    "# Display the first few rows of the DataFrame with the new 'label_num' column\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of X_train: (19200,)\n",
      "Shape of X_test: (4800,)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "label_num\n",
       "0    4800\n",
       "2    4800\n",
       "3    4800\n",
       "1    4800\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Import train_test_split for splitting the data into training and testing sets\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Split the data into training and testing sets, with stratification based on the label\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    df.Text,              # Input features (text data)\n",
    "    df.label_num,         # Target labels (numerical labels)\n",
    "    test_size=0.2,        # 20% of the data will be used for testing\n",
    "    random_state=2022,    # Set random seed for reproducibility\n",
    "    stratify=df.label_num # Ensure the split maintains the distribution of labels\n",
    ")\n",
    "\n",
    "# Print the shape (number of rows and columns) of the training data\n",
    "print(\"Shape of X_train:\", X_train.shape)\n",
    "\n",
    "# Print the shape of the testing data\n",
    "print(\"Shape of X_test:\", X_test.shape)\n",
    "\n",
    "# Display the count of each label in the training set\n",
    "y_train.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "label_num\n",
       "0    1200\n",
       "2    1200\n",
       "3    1200\n",
       "1    1200\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Display the count of each label in the testing set\n",
    "y_test.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.96      0.95      1200\n",
      "           1       0.96      0.97      0.97      1200\n",
      "           2       0.97      0.98      0.98      1200\n",
      "           3       0.98      0.95      0.96      1200\n",
      "\n",
      "    accuracy                           0.97      4800\n",
      "   macro avg       0.97      0.97      0.97      4800\n",
      "weighted avg       0.97      0.97      0.97      4800\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Import KNeighborsClassifier for classification using the k-nearest neighbors algorithm\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "# Import Pipeline to streamline the creation of machine learning workflows\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "# Import classification_report to evaluate the performance of the model\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "# Create a pipeline with two steps: TF-IDF vectorization and KNN classification\n",
    "clf = Pipeline([\n",
    "    (\"vectorizer_tfidf\", TfidfVectorizer()),    # Step 1: Convert text data to TF-IDF features\n",
    "    (\"KNN\", KNeighborsClassifier())             # Step 2: Apply KNN classification\n",
    "])\n",
    "\n",
    "# Fit the pipeline (train the model) on the training data\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "# Predict the labels for the testing data using the trained model\n",
    "y_pred = clf.predict(X_test)\n",
    "\n",
    "# Print the classification report to evaluate the performance of the model\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20706    Lal Haveli Designer Handmade Patchwork Decorat...\n",
       "19008    tirupur fashion biz Girls and Kids Solid Cotto...\n",
       "14810    Modern Linguistics: An Introduction About The ...\n",
       "2451     AmazonBasics Apple Certified 30-Pin to USB Cab...\n",
       "6296     The Marine Corps Martial Arts Program: The Com...\n",
       "Name: Text, dtype: object"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Display the first 5 samples of the testing data\n",
    "X_test[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20706    0\n",
       "19008    2\n",
       "14810    3\n",
       "2451     1\n",
       "6296     3\n",
       "Name: label_num, dtype: int64"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Display the true labels of the first 5 samples in the testing data\n",
    "y_test[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 2, 3, 1, 3])"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Display the predicted labels of the first 5 samples in the testing data\n",
    "y_pred[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.96      0.95      1200\n",
      "           1       0.96      0.96      0.96      1200\n",
      "           2       0.97      0.98      0.98      1200\n",
      "           3       0.98      0.93      0.95      1200\n",
      "\n",
      "    accuracy                           0.96      4800\n",
      "   macro avg       0.96      0.96      0.96      4800\n",
      "weighted avg       0.96      0.96      0.96      4800\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Import MultinomialNB for Naive Bayes classification\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "\n",
    "# Create a pipeline with TF-IDF vectorization and Multinomial Naive Bayes classification\n",
    "clf = Pipeline([\n",
    "    (\"vectorizer_tfidf\", TfidfVectorizer()),    # Step 1: Convert text data to TF-IDF features\n",
    "    (\"Multi NB\", MultinomialNB())               # Step 2: Apply Multinomial Naive Bayes classification\n",
    "])\n",
    "\n",
    "# Fit the pipeline on the training data\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "# Predict the labels for the testing data\n",
    "y_pred = clf.predict(X_test)\n",
    "\n",
    "# Print the classification report to evaluate the performance of the model\n",
    "print(classification_report(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.96      0.96      1200\n",
      "           1       0.97      0.97      0.97      1200\n",
      "           2       0.98      0.98      0.98      1200\n",
      "           3       0.98      0.97      0.97      1200\n",
      "\n",
      "    accuracy                           0.97      4800\n",
      "   macro avg       0.97      0.97      0.97      4800\n",
      "weighted avg       0.97      0.97      0.97      4800\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Import RandomForestClassifier for classification using the Random Forest algorithm\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# Create a pipeline with TF-IDF vectorization and Random Forest classification\n",
    "clf = Pipeline([\n",
    "    (\"vectorizer_tfidf\", TfidfVectorizer()),    # Step 1: Convert text data to TF-IDF features\n",
    "    (\"Random Forest\", RandomForestClassifier()) # Step 2: Apply Random Forest classification\n",
    "])\n",
    "\n",
    "# Fit the pipeline on the training data\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "# Predict the labels for the testing data\n",
    "y_pred = clf.predict(X_test)\n",
    "\n",
    "# Print the classification report to evaluate the performance of the model\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.96      0.95      1200\n",
      "           1       0.96      0.96      0.96      1200\n",
      "           2       0.97      0.98      0.98      1200\n",
      "           3       0.98      0.93      0.95      1200\n",
      "\n",
      "    accuracy                           0.96      4800\n",
      "   macro avg       0.96      0.96      0.96      4800\n",
      "weighted avg       0.96      0.96      0.96      4800\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "\n",
    "clf = Pipeline([\n",
    "    (\"vectorizer_tfidf\", TfidfVectorizer()),\n",
    "    (\"Multi NB\", MultinomialNB())\n",
    "])\n",
    "\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "y_pred = clf.predict(X_test)\n",
    "\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the spaCy library for natural language processing\n",
    "import spacy\n",
    "\n",
    "# Load the small English language model in spaCy and create an NLP object\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "\n",
    "# Define a function to preprocess text by removing stop words and punctuation, and lemmatizing the tokens\n",
    "def preprocess(text):\n",
    "    doc = nlp(text)               # Process the text to create a spaCy document object\n",
    "    filtered_token = []           # Initialize an empty list to store the filtered tokens\n",
    "    for token in doc:             # Loop through each token in the document\n",
    "        if token.is_stop or token.is_punct:  # Skip stop words and punctuation\n",
    "            continue\n",
    "        filtered_token.append(token.lemma_)  # Append the lemmatized form of the token to the list\n",
    "    return \" \".join(filtered_token)          # Join the tokens into a single string and return it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply the preprocess function to the 'Text' column in the DataFrame and create a new column 'preprocessed_txt'\n",
    "df[\"preprocessed_txt\"] = df[\"Text\"].apply(preprocess)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Text</th>\n",
       "      <th>label</th>\n",
       "      <th>label_num</th>\n",
       "      <th>preprocessed_txt</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Urban Ladder Eisner Low Back Study-Office Comp...</td>\n",
       "      <td>Household</td>\n",
       "      <td>0</td>\n",
       "      <td>Urban Ladder Eisner low Study Office Computer ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Contrast living Wooden Decorative Box,Painted ...</td>\n",
       "      <td>Household</td>\n",
       "      <td>0</td>\n",
       "      <td>contrast live Wooden Decorative Box Painted Bo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>IO Crest SY-PCI40010 PCI RAID Host Controller ...</td>\n",
       "      <td>Electronics</td>\n",
       "      <td>1</td>\n",
       "      <td>IO Crest SY PCI40010 PCI raid Host Controller ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ISAKAA Baby Socks from Just Born to 8 Years- P...</td>\n",
       "      <td>Clothing &amp; Accessories</td>\n",
       "      <td>2</td>\n",
       "      <td>ISAKAA Baby Socks bear 8 Years- Pack 4 6 8 12 ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Indira Designer Women's Art Mysore Silk Saree ...</td>\n",
       "      <td>Clothing &amp; Accessories</td>\n",
       "      <td>2</td>\n",
       "      <td>Indira Designer Women Art Mysore Silk Saree Bl...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                Text                   label  \\\n",
       "0  Urban Ladder Eisner Low Back Study-Office Comp...               Household   \n",
       "1  Contrast living Wooden Decorative Box,Painted ...               Household   \n",
       "2  IO Crest SY-PCI40010 PCI RAID Host Controller ...             Electronics   \n",
       "3  ISAKAA Baby Socks from Just Born to 8 Years- P...  Clothing & Accessories   \n",
       "4  Indira Designer Women's Art Mysore Silk Saree ...  Clothing & Accessories   \n",
       "\n",
       "   label_num                                   preprocessed_txt  \n",
       "0          0  Urban Ladder Eisner low Study Office Computer ...  \n",
       "1          0  contrast live Wooden Decorative Box Painted Bo...  \n",
       "2          1  IO Crest SY PCI40010 PCI raid Host Controller ...  \n",
       "3          2  ISAKAA Baby Socks bear 8 Years- Pack 4 6 8 12 ...  \n",
       "4          2  Indira Designer Women Art Mysore Silk Saree Bl...  "
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Display the first few rows of the DataFrame with the preprocessed text\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Urban Ladder Eisner Low Back Study-Office Computer Chair(Black) A study in simple. The Eisner study chair has a firm foam cushion, which makes long hours at your desk comfortable. The flexible meshed back is designed for air-circulation and support when you lean back. The curved arms provide ergonomic forearm support. Adjust the height using the gas lift to find that comfortable position and the nylon castors make it easy to move around your space. Chrome legs refer to the images for dimension details any assembly required will be done by the UL team at the time of delivery indoor use only.'"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Display the original text of the first row in the 'Text' column\n",
    "df.Text[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Urban Ladder Eisner low Study Office Computer Chair(Black study simple Eisner study chair firm foam cushion make long hour desk comfortable flexible mesh design air circulation support lean curved arm provide ergonomic forearm support adjust height gas lift find comfortable position nylon castor easy space chrome leg refer image dimension detail assembly require UL team time delivery indoor use'"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Display the preprocessed text of the first row in the 'preprocessed_txt' column\n",
    "df.preprocessed_txt[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.97      0.97      1200\n",
      "           1       0.97      0.98      0.98      1200\n",
      "           2       0.98      0.99      0.99      1200\n",
      "           3       0.98      0.98      0.98      1200\n",
      "\n",
      "    accuracy                           0.98      4800\n",
      "   macro avg       0.98      0.98      0.98      4800\n",
      "weighted avg       0.98      0.98      0.98      4800\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Split the data into training and testing sets using the preprocessed text and numerical labels\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    df.preprocessed_txt,  # Input features (preprocessed text)\n",
    "    df.label_num,         # Target labels (numerical labels)\n",
    "    test_size=0.2,        # 20% of the data will be used for testing\n",
    "    random_state=2022,    # Set random seed for reproducibility\n",
    "    stratify=df.label_num # Ensure the split maintains the distribution of labels\n",
    ")\n",
    "\n",
    "# Create a pipeline with TF-IDF vectorization and Random Forest classification using the preprocessed text\n",
    "clf = Pipeline([\n",
    "    (\"vectorizer_tfidf\", TfidfVectorizer()),    # Step 1: Convert preprocessed text to TF-IDF features\n",
    "    (\"Random Forest\", RandomForestClassifier()) # Step 2: Apply Random Forest classification\n",
    "])\n",
    "\n",
    "# Fit the pipeline on the training data\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "# Predict the labels for the testing data\n",
    "y_pred = clf.predict(X_test)\n",
    "\n",
    "# Print the classification report to evaluate the performance of the model\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tensorflow-test",
   "language": "python",
   "name": "tensorflow-test"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
